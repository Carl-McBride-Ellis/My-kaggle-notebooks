{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.005307,
     "end_time": "2020-09-11T15:45:57.065151",
     "exception": false,
     "start_time": "2020-09-11T15:45:57.059844",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## House Prices: How to work offline\n",
    "This is an example script for working 'offline' on the [House Prices: Advanced Regression Techniques](https://www.kaggle.com/c/house-prices-advanced-regression-techniques) competition. When working online you are limited to submitting a maximum of 5 entries per day. However, you may find this limit restrictive if you are trying out many ideas at the same time. The solution to this competition is in the public domain, so by either adding the [House Prices: Advanced Regression 'solution' file](https://www.kaggle.com/carlmcbrideellis/house-prices-advanced-regression-solution-file) to your notebook using the **+ Add data** option found on the top right of your notebook, or by downlading the `solution.csv` file locally to your computer, you can instead work totally offline. This will open up the possibility of experimenting with advanced techniques such as pipelines with various estimators in the same file, extensive hyper-parameter tuning etc.\n",
    "\n",
    "Below is an example script, which loads in both the competition files and the solution file, performs a simple random forest regression, and then evaluates the score, which is calculated using the root of the [mean squared logarithmic error regression loss](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_log_error.html), just as for the competition leaderboard, using [the following equation](https://scikit-learn.org/stable/modules/model_evaluation.html#mean-squared-log-error): <br>\n",
    "\n",
    "$$ {\\mathrm {RMSLE}}\\,(y, \\hat y) = \\sqrt{ \\frac{1}{n_{   \\mathrm{samples}    }}  \\sum_{i=0}^{n_{    \\mathrm{samples} }-1} \\left( \\ln (1+y_i) - \\ln (1+ \\hat y_i) \\right)^2 }  $$\n",
    "\n",
    "where $\\hat y_i$ is the predicted value of the $i$-th sample, and $y_i$ is the corresponding true value.\n",
    "\n",
    "**Note:** The score returned is not *exactly* the same as that given when you submit to the public leaderboard. This is because only 50% of predictions from the test set are assigned to the public leaderboard. The score you see on the public leaderboard reflects your modelâ€™s accuracy on this portion of the test set, whereas here you are using 100% of the predictions. Ideally you should also perform such a split, in order to prevent [overfitting](https://en.wikipedia.org/wiki/Overfitting).\n",
    "\n",
    "Here is the code. Please feel totally free to make a *fork* and then replace my trivial feature engineering and estimator with your own magnificent work!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2020-09-11T15:45:57.089857Z",
     "iopub.status.busy": "2020-09-11T15:45:57.089054Z",
     "iopub.status.idle": "2020-09-11T15:45:58.355215Z",
     "shell.execute_reply": "2020-09-11T15:45:58.355803Z"
    },
    "papermill": {
     "duration": 1.286286,
     "end_time": "2020-09-11T15:45:58.356027",
     "exception": false,
     "start_time": "2020-09-11T15:45:57.069741",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The score is 0.17690\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/python3\n",
    "# coding=utf-8\n",
    "#===========================================================================\n",
    "# This is a minimal script to perform a regression on the kaggle \n",
    "# 'House Prices' data set.\n",
    "#===========================================================================\n",
    "#===========================================================================\n",
    "# load up the libraries\n",
    "#===========================================================================\n",
    "import pandas  as pd\n",
    "import numpy   as np\n",
    "\n",
    "#===========================================================================\n",
    "# read in the competition data \n",
    "#===========================================================================\n",
    "train_data = pd.read_csv('../input/house-prices-advanced-regression-techniques/train.csv')\n",
    "test_data  = pd.read_csv('../input/house-prices-advanced-regression-techniques/test.csv')\n",
    "\n",
    "#===========================================================================\n",
    "# also, read in the 'solution' data \n",
    "# Note: you either need to use \"+ Add data\" to include this file if you are woking on kaggle,\n",
    "# or download it and store it locally if you are completely offline\n",
    "#===========================================================================\n",
    "solution   = pd.read_csv('../input/house-prices-advanced-regression-solution-file/solution.csv')\n",
    "y_true     = solution[\"SalePrice\"]\n",
    "                         \n",
    "#===========================================================================\n",
    "# select some features of interest\n",
    "#===========================================================================\n",
    "features = ['OverallQual', 'GrLivArea', 'GarageCars',  'TotalBsmtSF']\n",
    "\n",
    "#===========================================================================\n",
    "#===========================================================================\n",
    "X_train       = train_data[features]\n",
    "y_train       = train_data[\"SalePrice\"]\n",
    "final_X_test  = test_data[features]\n",
    "\n",
    "#===========================================================================\n",
    "# essential preprocessing: imputation; substitute any 'NaN' with mean value\n",
    "#===========================================================================\n",
    "X_train      = X_train.fillna(X_train.mean())\n",
    "final_X_test = final_X_test.fillna(final_X_test.mean())\n",
    "\n",
    "#===========================================================================\n",
    "# perform the regression and then the fit\n",
    "#===========================================================================\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "regressor = RandomForestRegressor(n_estimators=20, max_depth=7)\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "#===========================================================================\n",
    "# use the model to predict the prices for the test data\n",
    "#===========================================================================\n",
    "y_pred = regressor.predict(final_X_test)\n",
    "\n",
    "#===========================================================================\n",
    "# compare your predictions with the 'solution' using the \n",
    "# root of the mean_squared_log_error\n",
    "#===========================================================================\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "RMSLE = np.sqrt( mean_squared_log_error(y_true, y_pred) )\n",
    "print(\"The score is %.5f\" % RMSLE )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.00458,
     "end_time": "2020-09-11T15:45:58.366831",
     "exception": false,
     "start_time": "2020-09-11T15:45:58.362251",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "When you are finally ready to submit your work to the leaderboard, you can produce a `submission.csv` with the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-11T15:45:58.383706Z",
     "iopub.status.busy": "2020-09-11T15:45:58.382967Z",
     "iopub.status.idle": "2020-09-11T15:45:58.444808Z",
     "shell.execute_reply": "2020-09-11T15:45:58.443889Z"
    },
    "papermill": {
     "duration": 0.073352,
     "end_time": "2020-09-11T15:45:58.444946",
     "exception": false,
     "start_time": "2020-09-11T15:45:58.371594",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#===========================================================================\n",
    "# write out CSV submission file\n",
    "#===========================================================================\n",
    "output = pd.DataFrame({\"Id\":test_data.Id, \"SalePrice\":y_pred})\n",
    "output.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 12.79289,
   "end_time": "2020-09-11T15:45:58.558519",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-09-11T15:45:45.765629",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
