{
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "This is a minimalist script for classification of the 'Titanic' data set using the keras deep learning library. It produces a score of around 0.77511 (i.e. 324 out of 418 are correctly classified), but this is not good, nor is it the point: the purpose of this script is to serve as a basic starting baseline from which you can launch your own feature engineering, model/parameter tuning with a grid search, stratified k-fold cross validation, different activation functions, topology, etc etc.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "044470f4-457a-46ec-91ff-0121909bb282",
    "_uuid": "91cf55ca-fbff-4428-a877-045867963d99"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/python3\n",
    "# coding=utf-8\n",
    "#===========================================================================\n",
    "# This is a minimal baseline script to perform a classification on the \n",
    "# kaggle 'Titanic' data set, using the keras deep learning library \n",
    "# Carl McBride Ellis (14.IV.2020)\n",
    "#===========================================================================\n",
    "#===========================================================================\n",
    "# load up the libraries\n",
    "#===========================================================================\n",
    "import pandas  as pd\n",
    "from   keras.models import Sequential\n",
    "from   keras.layers import Dense             # i.e.fully connected\n",
    "\n",
    "#===========================================================================\n",
    "# read in the data\n",
    "#===========================================================================\n",
    "train_data = pd.read_csv('../input/titanic/train.csv')\n",
    "test_data  = pd.read_csv('../input/titanic/test.csv')\n",
    "\n",
    "#===========================================================================\n",
    "# select some features of interest (\"ay, there's the rub\", Shakespeare)\n",
    "#===========================================================================\n",
    "features = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\"]\n",
    "\n",
    "#===========================================================================\n",
    "# for the features that are categorical we use pd.get_dummies:\n",
    "# \"Convert categorical variable into dummy/indicator variables.\"\n",
    "#===========================================================================\n",
    "X_train       = pd.get_dummies(train_data[features])\n",
    "y_train       = train_data[\"Survived\"]\n",
    "final_X_test  = pd.get_dummies(test_data[features])\n",
    "\n",
    "#===========================================================================\n",
    "# parameters for keras\n",
    "#===========================================================================\n",
    "input_dim   = len(X_train.columns) # number of neurons in the input layer\n",
    "n_neurons   = 50            # number of neurons in the first hidden layer\n",
    "epochs      = 100           # number of training cycles\n",
    "\n",
    "#===========================================================================\n",
    "# keras model\n",
    "#===========================================================================\n",
    "model = Sequential()         # a model consisting of successive layers\n",
    "# input layer\n",
    "model.add(Dense(n_neurons, input_dim=input_dim, activation='relu'))\n",
    "# output layer, with one neuron\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "#===========================================================================\n",
    "# train the model\n",
    "#===========================================================================\n",
    "model.fit(X_train, y_train, epochs=epochs, verbose=0)\n",
    "\n",
    "#===========================================================================\n",
    "# use the trained model to predict 'Survived' for the test data\n",
    "#===========================================================================\n",
    "predictions = model.predict(final_X_test)\n",
    "# set a threshold of 50% for classification, i.e. >0.5 is True\n",
    "# Note: the '*1' converts the Boolean array into an array containing 0 or 1\n",
    "predictions = (predictions > 0.5)*1\n",
    "\n",
    "#===========================================================================\n",
    "# write out CSV submission file\n",
    "#===========================================================================\n",
    "output = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions.flatten()})\n",
    "output.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
